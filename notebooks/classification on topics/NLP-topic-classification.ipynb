{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF text extraction tool\n",
    "Author: Roald Teunissen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Scikit learn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# DuckDB for fast quering\n",
    "import duckdb\n",
    "\n",
    "# Word embedding\n",
    "import gensim\n",
    "from gensim.models import Word2Vec #Word2Vec is mostly used for huge datasets\n",
    "\n",
    "# Natural Language Toolkit\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import altair as alt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join(os.getcwd(), '../../data/')\n",
    "RAW_DATA_DIR = os.path.join(DATA_DIR, 'raw')\n",
    "PROCESSED_DATA_DIR = os.path.join(DATA_DIR, 'processed')\n",
    "\n",
    "PARQUET_NAME = 'paper_data.parquet'\n",
    "\n",
    "conn = duckdb.connect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(os.path.join(RAW_DATA_DIR, PARQUET_NAME), engine='fastparquet')\n",
    "data = data.rename(columns = {'topic': 'subject'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(data, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12482, 3)\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subject</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12482</td>\n",
       "      <td>12482</td>\n",
       "      <td>12482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>11555</td>\n",
       "      <td>8</td>\n",
       "      <td>11563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2301.07104</td>\n",
       "      <td>physics</td>\n",
       "      <td>LARGE DEVIATIONS FOR CLASSIFICATION PERFORMANC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4</td>\n",
       "      <td>1805</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id  subject                                            content\n",
       "count        12482    12482                                              12482\n",
       "unique       11555        8                                              11563\n",
       "top     2301.07104  physics  LARGE DEVIATIONS FOR CLASSIFICATION PERFORMANC...\n",
       "freq             4     1805                                                  4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-86886e3e7fc34296b3907159176a74ec\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-86886e3e7fc34296b3907159176a74ec\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-86886e3e7fc34296b3907159176a74ec\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}, \"title\": {\"fontSize\": 20}}, \"layer\": [{\"mark\": \"bar\", \"encoding\": {\"color\": {\"field\": \"subject_index\", \"legend\": null, \"title\": \"Subjects\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": 20}, \"field\": \"subject_index\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"axis\": {\"values\": [0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900]}, \"field\": \"value_counts\", \"title\": null, \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"dy\": -10, \"fontSize\": 15}, \"encoding\": {\"color\": {\"field\": \"subject_index\", \"legend\": null, \"title\": \"Subjects\", \"type\": \"nominal\"}, \"text\": {\"field\": \"value_counts\", \"type\": \"quantitative\"}, \"x\": {\"axis\": {\"labelAngle\": 20}, \"field\": \"subject_index\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"axis\": {\"values\": [0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900]}, \"field\": \"value_counts\", \"title\": null, \"type\": \"quantitative\"}}}], \"data\": {\"name\": \"data-4762cfb3f1657fc1035b5f815129c63c\"}, \"height\": 400, \"title\": \"Number of papers per subject\", \"width\": 500, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-4762cfb3f1657fc1035b5f815129c63c\": [{\"subject_index\": \"eess\", \"value_counts\": 1210}, {\"subject_index\": \"mathematics\", \"value_counts\": 1416}, {\"subject_index\": \"statistics\", \"value_counts\": 1355}, {\"subject_index\": \"physics\", \"value_counts\": 1460}, {\"subject_index\": \"q_finance\", \"value_counts\": 1101}, {\"subject_index\": \"q_biology\", \"value_counts\": 1219}, {\"subject_index\": \"computer_science\", \"value_counts\": 1394}, {\"subject_index\": \"economics\", \"value_counts\": 830}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_index = df_train['subject'].unique()\n",
    "value_counts = df_train['subject'].value_counts().reindex(index = subject_index)\n",
    "\n",
    "source = pd.DataFrame({\n",
    "    'subject_index': subject_index,\n",
    "    'value_counts': value_counts\n",
    "})\n",
    "\n",
    "bar_plot = alt.Chart(source).mark_bar().encode(\n",
    "    alt.X('subject_index', title = None, axis = alt.AxisConfig(labelAngle = 20)),\n",
    "    alt.Y('value_counts', title = None, axis = alt.Axis( values = [*range(0,2000, 100)])),\n",
    "    alt.Color('subject_index', title = 'Subjects', legend = None),\n",
    ")\n",
    "\n",
    "text = bar_plot.mark_text(dy = -10, fontSize = 15).encode(\n",
    "    text = alt.Text('value_counts'),\n",
    ")\n",
    "\n",
    "final_bar = (bar_plot + text).properties(\n",
    "    width = 500,\n",
    "    height = 400,\n",
    "    title = 'Number of papers per subject'\n",
    ").configure_title(\n",
    "    fontSize=20\n",
    ")\n",
    "final_bar"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, _economics_ has the lowest value with `852` and _computer science_ with `1415`.<br>\n",
    "From this we could either decide to pick 852 items from each subject, but I think it is a better idea to look at the number of words we are going to use for our model, since it relies on words rather than then number of papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id         0\n",
       "subject    0\n",
       "content    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing values\n",
    "df_train.isna().sum()\n",
    "\n",
    "# There are no missing values, as expected as this data is scraped and extracted from pdf files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['word_count'] = df_train['content'].apply(lambda x: len(str(x).split()))\n",
    "df_train['char_count'] = df_train['content'].apply(lambda x: len(str(x)))\n",
    "df_train['unique_word_count'] = df_train['content'].apply(lambda x: len(set(str(x).split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using DuckDB for fast querying\n",
    "# DuckDB uses a columnar-vectorized query execution engine, which makes it exceptionally fast for querying complex and aggregations\n",
    "# (notice that it is finished with querying over thousands of entries in 0.1s)\n",
    "# I suggest to check out this website if you want to learn more: https://duckdb.org/why_duckdb\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT\n",
    "        subject,\n",
    "        ROUND(SUM(char_count)) as 'char count',\n",
    "        ROUND(SUM(word_count)) as 'word count',\n",
    "        ROUND(SUM(unique_word_count)) as 'unique word count',\n",
    "        ROUND(MEAN(char_count)) as 'char count mean',\n",
    "        ROUND(MEAN(word_count)) as 'word count mean',\n",
    "        ROUND(MEAN(unique_word_count)) as 'unique word count mean'\n",
    "    FROM df_train\n",
    "    GROUP BY subject\n",
    "\"\"\"\n",
    "word_overview = conn.execute(query).df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>char count</th>\n",
       "      <th>word count</th>\n",
       "      <th>unique word count</th>\n",
       "      <th>char count mean</th>\n",
       "      <th>word count mean</th>\n",
       "      <th>unique word count mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eess</td>\n",
       "      <td>59317154.0</td>\n",
       "      <td>8950997.0</td>\n",
       "      <td>2936831.0</td>\n",
       "      <td>49022.0</td>\n",
       "      <td>7398.0</td>\n",
       "      <td>2427.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mathematics</td>\n",
       "      <td>87662768.0</td>\n",
       "      <td>12339533.0</td>\n",
       "      <td>4081124.0</td>\n",
       "      <td>61909.0</td>\n",
       "      <td>8714.0</td>\n",
       "      <td>2882.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>statistics</td>\n",
       "      <td>93781272.0</td>\n",
       "      <td>13841477.0</td>\n",
       "      <td>4280118.0</td>\n",
       "      <td>69211.0</td>\n",
       "      <td>10215.0</td>\n",
       "      <td>3159.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>physics</td>\n",
       "      <td>83526609.0</td>\n",
       "      <td>12672723.0</td>\n",
       "      <td>4055735.0</td>\n",
       "      <td>57210.0</td>\n",
       "      <td>8680.0</td>\n",
       "      <td>2778.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>q_finance</td>\n",
       "      <td>72865178.0</td>\n",
       "      <td>10805002.0</td>\n",
       "      <td>3401384.0</td>\n",
       "      <td>66181.0</td>\n",
       "      <td>9814.0</td>\n",
       "      <td>3089.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>q_biology</td>\n",
       "      <td>74388991.0</td>\n",
       "      <td>11127341.0</td>\n",
       "      <td>3494584.0</td>\n",
       "      <td>61025.0</td>\n",
       "      <td>9128.0</td>\n",
       "      <td>2867.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>computer_science</td>\n",
       "      <td>82224530.0</td>\n",
       "      <td>12341016.0</td>\n",
       "      <td>3928884.0</td>\n",
       "      <td>58985.0</td>\n",
       "      <td>8853.0</td>\n",
       "      <td>2818.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>economics</td>\n",
       "      <td>68323217.0</td>\n",
       "      <td>10147091.0</td>\n",
       "      <td>2884291.0</td>\n",
       "      <td>82317.0</td>\n",
       "      <td>12225.0</td>\n",
       "      <td>3475.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            subject  char count  word count  unique word count  \\\n",
       "0              eess  59317154.0   8950997.0          2936831.0   \n",
       "1       mathematics  87662768.0  12339533.0          4081124.0   \n",
       "2        statistics  93781272.0  13841477.0          4280118.0   \n",
       "3           physics  83526609.0  12672723.0          4055735.0   \n",
       "4         q_finance  72865178.0  10805002.0          3401384.0   \n",
       "5         q_biology  74388991.0  11127341.0          3494584.0   \n",
       "6  computer_science  82224530.0  12341016.0          3928884.0   \n",
       "7         economics  68323217.0  10147091.0          2884291.0   \n",
       "\n",
       "   char count mean  word count mean  unique word count mean  \n",
       "0          49022.0           7398.0                  2427.0  \n",
       "1          61909.0           8714.0                  2882.0  \n",
       "2          69211.0          10215.0                  3159.0  \n",
       "3          57210.0           8680.0                  2778.0  \n",
       "4          66181.0           9814.0                  3089.0  \n",
       "5          61025.0           9128.0                  2867.0  \n",
       "6          58985.0           8853.0                  2818.0  \n",
       "7          82317.0          12225.0                  3475.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_overview"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Barplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overview_plot(scope:list, graph_title:str, sub_titles:list, graph_width:int = 250, graph_height:int = 300):\n",
    "    char_count_bar = alt.Chart(word_overview[scope]).mark_bar().encode(\n",
    "        alt.X('subject', title = None, axis = alt.Axis(labelAngle=30)),\n",
    "        alt.Y(scope[1], title = None),\n",
    "        alt.Color('subject')\n",
    "    ).properties(\n",
    "        width = graph_width,\n",
    "        height = graph_height,\n",
    "        title = alt.TitleParams(\n",
    "            sub_titles[0],\n",
    "            fontWeight = 'lighter'\n",
    "        )\n",
    "    )\n",
    "    word_count_bar = alt.Chart(word_overview[scope]).mark_bar().encode(\n",
    "        alt.X('subject', title = None, axis = alt.Axis(labelAngle=30)),\n",
    "        alt.Y(scope[2], title = None),\n",
    "        alt.Color('subject')\n",
    "    ).properties(\n",
    "        width = graph_width,\n",
    "        height = graph_height,\n",
    "        title = alt.TitleParams(\n",
    "            sub_titles[1],\n",
    "            fontWeight = 'lighter'\n",
    "        )\n",
    "    )\n",
    "    unique_word_count_bar = alt.Chart(word_overview[scope]).mark_bar().encode(\n",
    "        alt.X('subject', title = None, axis = alt.Axis(labelAngle=30)),\n",
    "        alt.Y(scope[3], title = None),\n",
    "        alt.Color('subject')\n",
    "    ).properties(\n",
    "        width = graph_width,\n",
    "        height = graph_height,\n",
    "        title = alt.TitleParams(\n",
    "            sub_titles[2], \n",
    "            fontWeight = 'lighter'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return (char_count_bar | word_count_bar | unique_word_count_bar).properties(\n",
    "        title = alt.TitleParams(\n",
    "            graph_title, \n",
    "            anchor = 'middle', \n",
    "            fontWeight = 'bold',\n",
    "            fontSize = 20,\n",
    "            offset = 10,\n",
    "            lineHeight = 10\n",
    "        ),  padding = {'top': 10, 'left': 10, 'right': 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-6ed6ababe72a4e3b99cf62812dab7dfe\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-6ed6ababe72a4e3b99cf62812dab7dfe\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-6ed6ababe72a4e3b99cf62812dab7dfe\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"hconcat\": [{\"data\": {\"name\": \"data-78933376a3ec378610406868262a1e2a\"}, \"mark\": \"bar\", \"encoding\": {\"color\": {\"field\": \"subject\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": 30}, \"field\": \"subject\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"char count\", \"title\": null, \"type\": \"quantitative\"}}, \"height\": 300, \"title\": {\"text\": \"character\", \"fontWeight\": \"lighter\"}, \"width\": 250}, {\"data\": {\"name\": \"data-78933376a3ec378610406868262a1e2a\"}, \"mark\": \"bar\", \"encoding\": {\"color\": {\"field\": \"subject\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": 30}, \"field\": \"subject\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"word count\", \"title\": null, \"type\": \"quantitative\"}}, \"height\": 300, \"title\": {\"text\": \"word\", \"fontWeight\": \"lighter\"}, \"width\": 250}, {\"data\": {\"name\": \"data-78933376a3ec378610406868262a1e2a\"}, \"mark\": \"bar\", \"encoding\": {\"color\": {\"field\": \"subject\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": 30}, \"field\": \"subject\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"unique word count\", \"title\": null, \"type\": \"quantitative\"}}, \"height\": 300, \"title\": {\"text\": \"unique word\", \"fontWeight\": \"lighter\"}, \"width\": 250}], \"padding\": {\"top\": 10, \"left\": 10, \"right\": 10}, \"title\": {\"text\": \"Total per subject\", \"anchor\": \"middle\", \"fontSize\": 20, \"fontWeight\": \"bold\", \"lineHeight\": 10, \"offset\": 10}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-78933376a3ec378610406868262a1e2a\": [{\"subject\": \"eess\", \"char count\": 59317154.0, \"word count\": 8950997.0, \"unique word count\": 2936831.0}, {\"subject\": \"mathematics\", \"char count\": 87662768.0, \"word count\": 12339533.0, \"unique word count\": 4081124.0}, {\"subject\": \"statistics\", \"char count\": 93781272.0, \"word count\": 13841477.0, \"unique word count\": 4280118.0}, {\"subject\": \"physics\", \"char count\": 83526609.0, \"word count\": 12672723.0, \"unique word count\": 4055735.0}, {\"subject\": \"q_finance\", \"char count\": 72865178.0, \"word count\": 10805002.0, \"unique word count\": 3401384.0}, {\"subject\": \"q_biology\", \"char count\": 74388991.0, \"word count\": 11127341.0, \"unique word count\": 3494584.0}, {\"subject\": \"computer_science\", \"char count\": 82224530.0, \"word count\": 12341016.0, \"unique word count\": 3928884.0}, {\"subject\": \"economics\", \"char count\": 68323217.0, \"word count\": 10147091.0, \"unique word count\": 2884291.0}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overview_plot(['subject', 'char count', 'word count', 'unique word count'], 'Total per subject', ['character', 'word', 'unique word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-275c7efb1ffc4d50a7145d83d2bca3fb\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-275c7efb1ffc4d50a7145d83d2bca3fb\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-275c7efb1ffc4d50a7145d83d2bca3fb\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"hconcat\": [{\"data\": {\"name\": \"data-aad7f8f7e1ae4d27536fe2f73ddaa230\"}, \"mark\": \"bar\", \"encoding\": {\"color\": {\"field\": \"subject\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": 30}, \"field\": \"subject\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"char count mean\", \"title\": null, \"type\": \"quantitative\"}}, \"height\": 300, \"title\": {\"text\": \"character\", \"fontWeight\": \"lighter\"}, \"width\": 250}, {\"data\": {\"name\": \"data-aad7f8f7e1ae4d27536fe2f73ddaa230\"}, \"mark\": \"bar\", \"encoding\": {\"color\": {\"field\": \"subject\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": 30}, \"field\": \"subject\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"word count mean\", \"title\": null, \"type\": \"quantitative\"}}, \"height\": 300, \"title\": {\"text\": \"word\", \"fontWeight\": \"lighter\"}, \"width\": 250}, {\"data\": {\"name\": \"data-aad7f8f7e1ae4d27536fe2f73ddaa230\"}, \"mark\": \"bar\", \"encoding\": {\"color\": {\"field\": \"subject\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": 30}, \"field\": \"subject\", \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"unique word count mean\", \"title\": null, \"type\": \"quantitative\"}}, \"height\": 300, \"title\": {\"text\": \"unique word\", \"fontWeight\": \"lighter\"}, \"width\": 250}], \"padding\": {\"top\": 10, \"left\": 10, \"right\": 10}, \"title\": {\"text\": \"Average per subject (representing the average paper)\", \"anchor\": \"middle\", \"fontSize\": 20, \"fontWeight\": \"bold\", \"lineHeight\": 10, \"offset\": 10}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-aad7f8f7e1ae4d27536fe2f73ddaa230\": [{\"subject\": \"eess\", \"char count mean\": 49022.0, \"word count mean\": 7398.0, \"unique word count mean\": 2427.0}, {\"subject\": \"mathematics\", \"char count mean\": 61909.0, \"word count mean\": 8714.0, \"unique word count mean\": 2882.0}, {\"subject\": \"statistics\", \"char count mean\": 69211.0, \"word count mean\": 10215.0, \"unique word count mean\": 3159.0}, {\"subject\": \"physics\", \"char count mean\": 57210.0, \"word count mean\": 8680.0, \"unique word count mean\": 2778.0}, {\"subject\": \"q_finance\", \"char count mean\": 66181.0, \"word count mean\": 9814.0, \"unique word count mean\": 3089.0}, {\"subject\": \"q_biology\", \"char count mean\": 61025.0, \"word count mean\": 9128.0, \"unique word count mean\": 2867.0}, {\"subject\": \"computer_science\", \"char count mean\": 58985.0, \"word count mean\": 8853.0, \"unique word count mean\": 2818.0}, {\"subject\": \"economics\", \"char count mean\": 82317.0, \"word count mean\": 12225.0, \"unique word count mean\": 3475.0}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overview_plot(['subject', 'char count mean', 'word count mean', 'unique word count mean'], 'Average per subject (representing the average paper)', ['character', 'word', 'unique word'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These graphs show a whole different picture I first had in mind. The previous graph showed that _economics_ had the least amount of papers, which we had to scale down to, but it seems that _economics_ has far out the most amount of **characters**,**word count** and **unique word count**. This implies that _economic_ papers tend to be more comprehensive."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['clean_text_tok'] = [nltk.word_tokenize(i) for i in df_train['content']] # Tokenize content (might take 15mins)\n",
    "\n",
    "model = Word2Vec(df_train['clean_text_tok'], min_count = 1)\n",
    "\n",
    "w2v = dict(zip(model.wv.index_to_key, model.wv.vectors))  # Combine word and its vector\n",
    "\n",
    "# For converting sentence to vectors/numbers from word vectors result by Word2Vec\n",
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        # if a text is empty we should return a vector of zeros\n",
    "        # with the same dimensionality as all the other vectors\n",
    "        self.dim = len(next(iter(word2vec.values())))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.word2vec[w] for w in words if w in self.word2vec]\n",
    "                    or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(df_train[\"content\"],\n",
    "                                                  df_train[\"subject\"],\n",
    "                                                  test_size = 0.2,\n",
    "                                                  shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert value\n",
    "y_val = y_val.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize for word2vec\n",
    "X_train_tok = [nltk.word_tokenize(i) for i in X_train]\n",
    "X_val_tok = [nltk.word_tokenize(i) for i in X_val]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF preparation\n",
    "\n",
    "In short:<br>\n",
    "_Short for **term frequencyâ€“inverse document frequency**, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize vectorizer to prepare the data for our model\n",
    "tfidf_vectorizer = TfidfVectorizer(use_idf = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize train and validation data\n",
    "X_train_vectors_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_val_vectors_tfidf = tfidf_vectorizer.transform(X_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we only fit the training data with our vectorizer's `fit_transform()` function.<br>\n",
    "This will set the word-indexes and weights to match the training data.\n",
    "\n",
    "### Word2vec preperation\n",
    "\n",
    "In short: <br>\n",
    "_As the name implies, **word2vec** represents each distinct word with a particular list of numbers called a vector. The vectors are chosen carefully such that they capture the semantic and syntactic qualities of words; as such, a simple mathematical function (cosine similarity) can indicate the level of semantic similarity between the words represented by those vectors._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize word embedding model\n",
    "modelw = MeanEmbeddingVectorizer(w2v)\n",
    "\n",
    "X_train_vectors_w2v = modelw.transform(X_train_tok)\n",
    "X_val_vectors_w2v = modelw.transform(X_val_tok)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building ML models for text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OrdinalEncoder() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix for multiple dimensions. This seems to be hard to realize so a solution may be implemented later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color = ['Blues', 'Oranges', 'Reds', 'PuBu', 'Greens', 'YlOrBr', 'Purples', 'RdPu']\n",
    "\n",
    "# def plot_confusion_matrix(y_test, y_pred, subjects):\n",
    "#     f, axes = plt.subplots(2, 4, figsize=(25, 10))\n",
    "    \n",
    "#     axes = axes.ravel()\n",
    "#     for i, subject in enumerate(subjects):        \n",
    "#         disp = ConfusionMatrixDisplay(confusion_matrix(y_test[:, i],\n",
    "#                                                     y_pred[:, i]),\n",
    "#                                     display_labels=[0, i])\n",
    "#         disp.plot(ax=axes[i], values_format='.4g', cmap = color[i])\n",
    "#         disp.ax_.set_title(subject)\n",
    "#         if i<10:\n",
    "#             disp.ax_.set_xlabel('')\n",
    "#         if i%5!=0:\n",
    "#             disp.ax_.set_ylabel('')\n",
    "#         disp.im_.colorbar.remove()\n",
    "\n",
    "#     plt.subplots_adjust(wspace=0.10, hspace=0.1)\n",
    "#     f.colorbar(disp.im_, ax=axes)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['eess'],\n",
       " ['mathematics'],\n",
       " ['statistics'],\n",
       " ['physics'],\n",
       " ['q_finance'],\n",
       " ['q_biology'],\n",
       " ['computer_science'],\n",
       " ['economics']]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reiterate what our unique values are\n",
    "[[unique_val] for unique_val in df_train[\"subject\"].unique()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and fit model\n",
    "lr_tfidf = LogisticRegression(solver = 'liblinear', C=10, penalty = 'l2')\n",
    "lr_tfidf.fit(X_train_vectors_tfidf, y_train)\n",
    "\n",
    "# Make a prediction on the validation data\n",
    "lr_tfidf_y_predict = lr_tfidf.predict(X_val_vectors_tfidf) \n",
    "lr_tfidf_y_prob = lr_tfidf.predict_proba(X_val_vectors_tfidf)[:,1] \n",
    "\n",
    "# Encode from topics [a,b,c,d] to numbers [1., 2., 3., 4.]\n",
    "lr_tfidf_y_predict = encoder.fit_transform(lr_tfidf_y_predict.reshape(-1,1))\n",
    "lr_tfidf_y_val = encoder.fit_transform(y_val.reshape(-1,1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse the performance our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.48      0.50       285\n",
      "         1.0       0.81      0.68      0.74       178\n",
      "         2.0       0.66      0.69      0.68       242\n",
      "         3.0       0.68      0.75      0.72       273\n",
      "         4.0       0.81      0.83      0.82       288\n",
      "         5.0       0.77      0.76      0.76       245\n",
      "         6.0       0.85      0.79      0.82       215\n",
      "         7.0       0.58      0.65      0.61       271\n",
      "\n",
      "    accuracy                           0.70      1997\n",
      "   macro avg       0.71      0.70      0.71      1997\n",
      "weighted avg       0.70      0.70      0.70      1997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(lr_tfidf_y_val, lr_tfidf_y_predict))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With multiple dimensions, plotting a ROC curve might be hard to do. An implementation may come later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fpr, tpr, thresholds = roc_curve(y_val, lr_tfidf_y_prob)\n",
    "\n",
    "# # Create ROC curve\n",
    "# plt.plot(fpr,tpr)\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes with tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and fit model\n",
    "nb_tfidf = MultinomialNB()\n",
    "nb_tfidf.fit(X_train_vectors_tfidf, y_train)\n",
    "\n",
    "# Make a prediction on the validation data\n",
    "nb_tfidf_y_predict = nb_tfidf.predict(X_val_vectors_tfidf)\n",
    "nb_tfidf_y_prob = nb_tfidf.predict_proba(X_val_vectors_tfidf)[:,1]\n",
    "\n",
    "# Encode from topics [a,b,c,d] to numbers [1., 2., 3., 4.]\n",
    "nb_tfidf_y_predict = encoder.fit_transform(nb_tfidf_y_predict.reshape(-1,1))\n",
    "nb_tfidf_y_val = encoder.fit_transform(y_val.reshape(-1,1)) # 111111"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse the performance our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.41      0.72      0.52       285\n",
      "         1.0       0.75      0.02      0.03       178\n",
      "         2.0       0.80      0.30      0.43       242\n",
      "         3.0       0.61      0.77      0.68       273\n",
      "         4.0       0.77      0.83      0.80       288\n",
      "         5.0       0.85      0.47      0.61       245\n",
      "         6.0       0.83      0.54      0.65       215\n",
      "         7.0       0.42      0.71      0.53       271\n",
      "\n",
      "    accuracy                           0.58      1997\n",
      "   macro avg       0.68      0.55      0.53      1997\n",
      "weighted avg       0.67      0.58      0.55      1997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(nb_tfidf_y_val, nb_tfidf_y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_confusion_matrix(y_val, y_predict)\n",
    "# plot_confusion_matrix(nb_tfidf_y_val, nb_tfidf_y_predict, df_train[\"subject\"].unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and fit model\n",
    "lr_w2v = LogisticRegression(solver = 'liblinear', C = 10, penalty = 'l2')\n",
    "lr_w2v.fit(X_train_vectors_w2v, y_train)  #model\n",
    "\n",
    "# Make a prediction on the validation data\n",
    "lr_w2v_y_predict = lr_w2v.predict(X_val_vectors_w2v)\n",
    "lr_w2v_y_prob = lr_w2v.predict_proba(X_val_vectors_w2v)[:,1]\n",
    "\n",
    "# Encode from topics [a,b,c,d] to numbers [1., 2., 3., 4.]\n",
    "lr_w2v_y_predict = encoder.fit_transform(lr_w2v_y_predict.reshape(-1,1))\n",
    "lr_w2v_y_val = encoder.fit_transform(y_val.reshape(-1,1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse the performance our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.52      0.55       285\n",
      "         1.0       0.74      0.66      0.69       178\n",
      "         2.0       0.63      0.68      0.65       242\n",
      "         3.0       0.71      0.81      0.76       273\n",
      "         4.0       0.84      0.81      0.82       288\n",
      "         5.0       0.72      0.72      0.72       245\n",
      "         6.0       0.78      0.76      0.77       215\n",
      "         7.0       0.60      0.62      0.61       271\n",
      "\n",
      "    accuracy                           0.70      1997\n",
      "   macro avg       0.70      0.70      0.70      1997\n",
      "weighted avg       0.70      0.70      0.70      1997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(lr_w2v_y_val, lr_w2v_y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_w2v_heatmap = plot_confusion_matrix(y_val, y_predict)\n",
    "# plot_confusion_matrix(y_val, y_predict, df_train[\"subject\"].unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With multiple dimensions, plotting a ROC curve might be hard to do. An implementation may come later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create ROC curve\n",
    "# plt.plot(fpr,tpr)\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on unlabelled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting X_test to vector\n",
    "X_test = df_test['content'] \n",
    "X_test_vec = tfidf_vectorizer.transform(X_test)\n",
    "X_test_vec_w2v = modelw.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose a model:\n",
    "Run one of the cells to make a prediction with a specific model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subject</th>\n",
       "      <th>predicted_topic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2301.04063</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2212.08890</td>\n",
       "      <td>statistics</td>\n",
       "      <td>statistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2301.00890</td>\n",
       "      <td>statistics</td>\n",
       "      <td>statistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2301.02912</td>\n",
       "      <td>q_finance</td>\n",
       "      <td>mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2209.10545</td>\n",
       "      <td>q_biology</td>\n",
       "      <td>q_biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2301.00159</td>\n",
       "      <td>q_biology</td>\n",
       "      <td>q_biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2212.04377</td>\n",
       "      <td>q_biology</td>\n",
       "      <td>q_biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2208.13675</td>\n",
       "      <td>q_biology</td>\n",
       "      <td>q_biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2301.02491</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2205.14517</td>\n",
       "      <td>economics</td>\n",
       "      <td>economics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2301.07842</td>\n",
       "      <td>eess</td>\n",
       "      <td>eess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2301.06006</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2301.08063</td>\n",
       "      <td>physics</td>\n",
       "      <td>physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2212.05805</td>\n",
       "      <td>eess</td>\n",
       "      <td>eess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2301.04237</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2212.10053</td>\n",
       "      <td>q_finance</td>\n",
       "      <td>q_finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2210.01592</td>\n",
       "      <td>q_biology</td>\n",
       "      <td>statistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2301.06805</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2301.09014</td>\n",
       "      <td>physics</td>\n",
       "      <td>physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2301.05730</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>mathematics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id      subject predicted_topic\n",
       "index                                         \n",
       "6      2301.04063  mathematics     mathematics\n",
       "9      2212.08890   statistics      statistics\n",
       "7      2301.00890   statistics      statistics\n",
       "7      2301.02912    q_finance     mathematics\n",
       "10     2209.10545    q_biology       q_biology\n",
       "2      2301.00159    q_biology       q_biology\n",
       "8      2212.04377    q_biology       q_biology\n",
       "10     2208.13675    q_biology       q_biology\n",
       "9      2301.02491  mathematics     mathematics\n",
       "3      2205.14517    economics       economics\n",
       "5      2301.07842         eess            eess\n",
       "0      2301.06006  mathematics     mathematics\n",
       "2      2301.08063      physics         physics\n",
       "7      2212.05805         eess            eess\n",
       "3      2301.04237  mathematics     mathematics\n",
       "0      2212.10053    q_finance       q_finance\n",
       "6      2210.01592    q_biology      statistics\n",
       "2      2301.06805  mathematics     mathematics\n",
       "9      2301.09014      physics         physics\n",
       "9      2301.05730  mathematics     mathematics"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression TF-IDF\n",
    "df_test['predicted_topic'] = lr_tfidf.predict(X_test_vec)\n",
    "df_test['predict_prob'] = lr_tfidf.predict_proba(X_test_vec)[:,1]\n",
    "\n",
    "# plot_confusion_matrix(df_test['topic'], df_test['predicted_topic']) # may come later\n",
    "df_test.drop(['content', 'predict_prob'], axis=1).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subject</th>\n",
       "      <th>predicted_topic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2301.04063</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2212.08890</td>\n",
       "      <td>statistics</td>\n",
       "      <td>statistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2301.00890</td>\n",
       "      <td>statistics</td>\n",
       "      <td>statistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2301.02912</td>\n",
       "      <td>q_finance</td>\n",
       "      <td>mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2209.10545</td>\n",
       "      <td>q_biology</td>\n",
       "      <td>q_biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2301.00159</td>\n",
       "      <td>q_biology</td>\n",
       "      <td>statistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2212.04377</td>\n",
       "      <td>q_biology</td>\n",
       "      <td>computer_science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2208.13675</td>\n",
       "      <td>q_biology</td>\n",
       "      <td>computer_science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2301.02491</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2205.14517</td>\n",
       "      <td>economics</td>\n",
       "      <td>computer_science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2301.07842</td>\n",
       "      <td>eess</td>\n",
       "      <td>computer_science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2301.06006</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2301.08063</td>\n",
       "      <td>physics</td>\n",
       "      <td>physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2212.05805</td>\n",
       "      <td>eess</td>\n",
       "      <td>computer_science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2301.04237</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2212.10053</td>\n",
       "      <td>q_finance</td>\n",
       "      <td>q_finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2210.01592</td>\n",
       "      <td>q_biology</td>\n",
       "      <td>statistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2301.06805</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2301.09014</td>\n",
       "      <td>physics</td>\n",
       "      <td>physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2301.05730</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>mathematics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id      subject   predicted_topic\n",
       "index                                           \n",
       "6      2301.04063  mathematics       mathematics\n",
       "9      2212.08890   statistics        statistics\n",
       "7      2301.00890   statistics        statistics\n",
       "7      2301.02912    q_finance       mathematics\n",
       "10     2209.10545    q_biology         q_biology\n",
       "2      2301.00159    q_biology        statistics\n",
       "8      2212.04377    q_biology  computer_science\n",
       "10     2208.13675    q_biology  computer_science\n",
       "9      2301.02491  mathematics       mathematics\n",
       "3      2205.14517    economics  computer_science\n",
       "5      2301.07842         eess  computer_science\n",
       "0      2301.06006  mathematics       mathematics\n",
       "2      2301.08063      physics           physics\n",
       "7      2212.05805         eess  computer_science\n",
       "3      2301.04237  mathematics       mathematics\n",
       "0      2212.10053    q_finance         q_finance\n",
       "6      2210.01592    q_biology        statistics\n",
       "2      2301.06805  mathematics       mathematics\n",
       "9      2301.09014      physics           physics\n",
       "9      2301.05730  mathematics       mathematics"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes TF-IDF\n",
    "df_test['predicted_topic'] = nb_tfidf.predict(X_test_vec)\n",
    "df_test['predict_prob'] = nb_tfidf.predict_proba(X_test_vec)[:,1]\n",
    "\n",
    "# plot_confusion_matrix(df_test['topic'], df_test['predicted_topic']) # may come later\n",
    "df_test.drop(['content', 'predict_prob'], axis=1).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subject</th>\n",
       "      <th>predicted_topic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2301.04063</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>computer_science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2212.08890</td>\n",
       "      <td>statistics</td>\n",
       "      <td>computer_science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2301.00890</td>\n",
       "      <td>statistics</td>\n",
       "      <td>computer_science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2301.02912</td>\n",
       "      <td>q_finance</td>\n",
       "      <td>computer_science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2209.10545</td>\n",
       "      <td>q_biology</td>\n",
       "      <td>computer_science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2301.00159</td>\n",
       "      <td>q_biology</td>\n",
       "      <td>computer_science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2212.04377</td>\n",
       "      <td>q_biology</td>\n",
       "      <td>computer_science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2208.13675</td>\n",
       "      <td>q_biology</td>\n",
       "      <td>computer_science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2301.02491</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>computer_science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2205.14517</td>\n",
       "      <td>economics</td>\n",
       "      <td>computer_science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2301.07842</td>\n",
       "      <td>eess</td>\n",
       "      <td>computer_science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2301.06006</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2301.08063</td>\n",
       "      <td>physics</td>\n",
       "      <td>computer_science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2212.05805</td>\n",
       "      <td>eess</td>\n",
       "      <td>computer_science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2301.04237</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>computer_science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2212.10053</td>\n",
       "      <td>q_finance</td>\n",
       "      <td>computer_science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2210.01592</td>\n",
       "      <td>q_biology</td>\n",
       "      <td>computer_science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2301.06805</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>computer_science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2301.09014</td>\n",
       "      <td>physics</td>\n",
       "      <td>economics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2301.05730</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>computer_science</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id      subject   predicted_topic\n",
       "index                                           \n",
       "6      2301.04063  mathematics  computer_science\n",
       "9      2212.08890   statistics  computer_science\n",
       "7      2301.00890   statistics  computer_science\n",
       "7      2301.02912    q_finance  computer_science\n",
       "10     2209.10545    q_biology  computer_science\n",
       "2      2301.00159    q_biology  computer_science\n",
       "8      2212.04377    q_biology  computer_science\n",
       "10     2208.13675    q_biology  computer_science\n",
       "9      2301.02491  mathematics  computer_science\n",
       "3      2205.14517    economics  computer_science\n",
       "5      2301.07842         eess  computer_science\n",
       "0      2301.06006  mathematics       mathematics\n",
       "2      2301.08063      physics  computer_science\n",
       "7      2212.05805         eess  computer_science\n",
       "3      2301.04237  mathematics  computer_science\n",
       "0      2212.10053    q_finance  computer_science\n",
       "6      2210.01592    q_biology  computer_science\n",
       "2      2301.06805  mathematics  computer_science\n",
       "9      2301.09014      physics         economics\n",
       "9      2301.05730  mathematics  computer_science"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression word2vec\n",
    "df_test['predicted_topic'] = lr_w2v.predict(X_test_vec_w2v)\n",
    "df_test['predict_prob'] = lr_w2v.predict_proba(X_test_vec_w2v)[:,1]\n",
    "\n",
    "# plot_confusion_matrix(df_test['topic'], df_test['predicted_topic']) # may come later\n",
    "df_test.drop(['content', 'predict_prob'], axis=1).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paper-text-classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1a4ce1929897f4fc22774caf51f2dd777e19a466651e718034b31bf7871224ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
